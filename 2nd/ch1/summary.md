# 1장 쿠버네티스 소개
쿠버네티스의 등장 배경
- 모놀리스에서 마이크로서비스로 전환
- 이 과정에서 배포 가능한 구성 요소 수가 많아지고 데이터 센터의 규모가 커지면서 전체 시스템을 원활하게 구성, 관리, 유지하는 일이 점점 어려워졌다
- 수동으로 이를 관리하는 것은 어렵기 때문에 서버 배포를 자동으로 스케줄링하고, 구성, 관리, 장애 처리를 포함하는 자동화의 필요성과 함께 등장

## 쿠버네티스와 같은 시스템이 필요한 이유
마이크로 서비스의 특징
- 마이크로서비스는 대체로 정적인 외부 API를 제공하는 독립형 프로세스이기 때문에 개별적으로 개발, 배포할 수 있다. 다른 시스템과 호환성을 유지할 수 있다면, 다른 서비스의 변경없이 변경된 서비스만 배포할 수 있다. 
- 각 서비스 단위로 확장 가능하다

마이크로 서비스 단점
- 구성 요소가 많아지면 서로를 찾아서 통신해야하는데 전체 시스템을 하나의 시스템처럼 구성하는 작업이 어려워진다. 
- 시스템이 분산되어 있기 때문에 버그를 추적하고 트랜잭션을 관리하기가 어렵다.

## 컨테이너 기술 소개
가상머신과 컨테이너
- 가상머신
   - 호스트 OS위에 하이퍼바이저가 있고, 그 위에 각각의 게스트 OS가 올라가서 동작한다
   - OS가 올라가는 오버헤드가 있기 때문에(= 구성 요소의 프로세스뿐만 아니라 시스템 프로세스를 실행해야하기 때문에) 각 애플리케이션 별로 하나의 VM 전용으로 사용하기에는 리소스가 충분하지 않다. 따라서 각 머신에 여러 애플리케이션을 그룹으로 배포하는 경우가 종종 있다.
   - 가상 머신 내의 애플리케이션이 게스트 OS 커널에 시스템 콜을 수행하면, 커널은 하이퍼바이저로 호스트의 물리적 CPU에서 x86명령을 수행한다. 
- 컨테이너
   - 호스트 OS위에서 프로세스 단위로 실행된다. 각각의 프로세스는 다른 프로세스와 격리되어 있기 때문에, 프로세스 입장에서 보면 시스템과 운영체제에서 실행되는 유일한 프로세스인 것처럼 보인다. 
   - 가상머신에 비해서 오버헤드가 적다. 
   - 각 컨테이너는 모드 동일한 OS에서 실행되므로 컨테이너는 시스템 서비스를 실행하지 않는다. 부팅이 필요없고, 컨테이너에서 시작되는 프로세스는 즉시 시작된다. 

리눅스의 격리 매커니즘
- 네임스페이스 격리
   - 프로세스는 동일한 네임스페이스 내에 있는 리소스만 볼 수 있다. 여러 종류의 네임스페이스가 있기 때문에 프로세스는 하나의 네임스페이스에만 속하는 것이 아니라 여러 네임스페이스에 속할 수 있다. 
   - 각 네임스페이스는 특정 리소스 그룹을 격리하는데 사용된다. 
      - 예를 들어 2개의 서로 다른 UTS 네임스페이스를 한 쌍의 프로세스에 각각 지정하면 서로 다른 로컬 호스트 이름을 보게 할 수 있다. 
- 리눅스 컨트롤 그룹(cgroups)
   - 컨테이너가 사용할 수 있는 시스템 리소스의 양을 제한할 수 있다. (CPU, 메모리, 네트워크 대역폭 등)

도커 컨테이너 플랫폼
- 개념
   - 이미지: 애플리케이과 해당 환경을 패키지화 한 것. 애플리케이션에서 사용할 수 있는 파일시스템과 이미지가 실행될 때 실행돼야 하는 실행파일 경로와 같은 메타데이터가 포함되어 있다. 
   - 레지스트리: 공유 가능한 이미지 저장소.
   - 컨테이너: 도커 기반 컨테이너 이미지에서 생성된 리눅스 컨테이너. 격리된 프로세스로 실행된다. 
- 이미지 레이어
   - 도커 이미지는 레이어로 구성되어 있고, 모든 도커 이미지는 다른 이미지 위에 빌드된다. 
   - 각 레이어는 동일 호스트에 한 번만 저장되기 때문에 스토리지 공간을 줄이는데 도움이 된다. 

## 쿠버네티스 소개
추상화
- 쿠버네티스를 소개하면 모든 노드가 하나의 거대한 컴퓨터인 것처럼 수천 대의 컴퓨터 노드에서 애플리케이션을 실행할 수 있다.
- 기본 인프라를 추상화하고 개발과 운영 팀 모두의 개발, 배포, 관리를 단순화한다. 
- 구성 요소가 어떤 노드에 배포되고 실행되던지 개발자나 시스템 관리자에게는 중요하지 않다. 
   - 서비스디스커버리, 스케일링, 로드밸런싱, 자가 치유, 리더 선출 같은 것들은 쿠버네티스에서 지원해준다. 

구성 및 아키텍처
- 1개의 마스터 노드(컨트롤 플레인)
   - API 서버: 사용자의 요청을 받고, 컨트롤 플레인 구성 요소와 통신한다. 컨트롤 플레인 내 각 요소는 API 서버를 통해서만 통신한다. 
   - etcd: 클러스터의 구성을 지속적으로 저장할 수 있는 분산 데이터 저장소. API 서버를 통해서만 통신한다. 
   - 스케줄러: 애플리케이션의 배포를 담당. 배포 가능한 각 구성요소를 워크 노드에 할당한다. 
   - 컨트롤러 매니저: 구성 요소 복제본, 워커 노드 추적, 노드 장애 처리 등과 같은 클러스터 단의 기능을 수행한다.
- 1개 이상의 워커 노드: 컨테이너화된 애플레키이션을 실행하는 시스템.
   - kubelet: API 서버와 통신하고 노트의 컨테이너를 관리한다.
   - 컨테이너 런타임: 컨테이너를 실행.
   - kube-proxy: 애플리케이션 구성요소 간에 네트워크 트래픽을 로드밸런싱한다.
      - 컨트롤 플레인에서 service의 대상 정보가 endpoint에 저장. 
      - kube-proxy가 endpoint의 정보를 워커논드의 iptables에 계속 동기화
      - 파드가 다른 파드를 참조할 때 iptables를 보고 참조. 

애플리케이션 실행 
1. 애플리케이션을 하나 이상의 컨테이너 이미지로 패키징
2. 이미지를 레지스트리(도커 허브, ECR)에 푸쉬
3. API 서버에 애플리케이션 디스크립션을 게시. 
   - 디스크립션에는 컨테이너 이미지, 애플리케이션 구성 요소가 포함된 이미지, 해당 구성 요소가 서로 통신하는 방법, 동일 서버에 함께 배치돼야 하는 구성요소와 같은 정보가 포함된다. 
   - yaml 파일을 만들어서 kubectl로 실행
   - API 서버는 변경 사항을 etcd에 저장
4. 스케줄러는 API 서버를 통해서 변경 사항을 확인하고, 각 컨테이너에 포함된 리소스를 계산한다. 그리고 사용가능한 워커노드에 지정된 컨테이너를 할당한다. 
5. 해당 노드의 kubelet은 변경 사항을 확인하고 컨테이너 런타임에 필요한 이미지를 가져와서 컨테이너를 실행하도록 지시한다. 

특징
- 애플리케이션 유지
   - 쿠버네티스는 애플리케이션의 배송 상태가 사용자가 제공한 디스크립션과 일치하는지 지속적으로 확인한다.
   - 프로세스 또는 노드가 중단되거나 응답이 중단될 때와 같이 인스턴스가 제대로 동작하지 않으면 다시 작동시킨다. (레디니스 프로브, 라이브니스 프로브)
- 메트릭을 기반으로 스케일링 조정
- 애플리케이션의 이동과 접근
   - 워커노드가 중지 또는 삭제되면 노드에서 실행중인 컨테이너는 다른 워커노드로 이동하게 된다. 
   - 그럼 어떻게 변경된 컨테이너를 찾아갈까? 쿠버네티스는 특정 서비스를 제공하는 컨테이너를 쉽게 찾을 수 있도록 하나의 고정 IP 주소(클러스터 IP) 컨테이너를 노출한다. 
   - kube-proxy가 로드밸런싱을 지원한다. 
