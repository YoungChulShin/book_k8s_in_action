# 5장 서비스
## 서비스 소개
개념
- 동일한 서비스를 제공하는 파드 그룹에 지속적인 단일 접점을 만들려고할 때 생성하는 리소스
   - 파드는 일시적이다
- 변경되지 않는 IP와 포트가 있다

서비스와 파드의 연결
- 서비스에서 레이블 셀렉터를 정의한다
   ```yaml
   spec:
    selector:
      app: kubia
   ```

쿠버네티스에서 실행중인 파드에 원격으로 명령을 보내는 방법
- `kubectl exec pod-name -- 명령어`
   ```
   // kubia-test라는 파드에 curl 명렁을 전달하는 예시
   kubectl exec kubia-test -- curl -s http://10.0.0.44
   ```

서비스는 기본적으로 여러 파드로 요청을 보내고, 특정 파드로만 요청을 보내려면 `sessionAffinity` 속성을 `ClientIP`로 변경한다
- 동일한 IP에 대해서는 동일한 파드로 전달
- _이렇게되면 파드에 부하분산이 되지 않기 때문에 큰 이점은 잘 모르겠다_

서비스에 여러 포트를 매핑하는 것은 ports 속성에 여러 port를 정의하면서 가능한데, 레이블 셀렉터는 전체 서비스에 적용되기 때문에, 개별적으로 구성을 하려면 2개의 서비스를 만들어야한다. 

### 서비스 검색
환경 변수를 통한 검색
- 파드가 시작될 때 서비스를 가리키는 환경변수 세트를 초기화한다
- `kubectl exec <<pod name>> env` 명령어로 서비스의 IP와 포트 정보를 확인 가능하다
   ```
   KUBIA_SERVICE_HOST=XXX
   KUBIA_SERVICE_PORT=80
   ```

DNS를 이용한 검색
- core_dns (예전 kube_dns) 서비스가 실행 중

FQDN을 통한 서비스 연결
- `target-service.default.svc.cluster.local`
   - target-service: 서비스 이름
   - default: 네임스페이스
   - svc.cluster.local: 모든 클러스트의 로컬 서비스 이름이 사용되는 도메인 접미사
- 2개의 파드가 같은 네임스페이스에 있다면 '네임스페이스'와 '도메인 접미사'는 생략 가능하기 때문에 서비스 이름으로 호출 할 수 있다
- 파드 내부에 `DNS resolver`가 구성되어 있다
   - etc/resolv.conf
     ```
     root@kubia-59kxt:/etc# cat resolv.conf
     nameserver 10.96.0.10
     search default.svc.cluster.local svc.cluster.local cluster.local
     options ndots:5
     ```
- 참고 사이트: https://jonnung.dev/kubernetes/2020/05/11/kubernetes-dns-about-coredns/

## 클러스터 외부에 서비스 연결
서비스 엔드포인트
- 서비스가 얀결하는 파드의 IP/Port 정보 리스트
- 서비스의 describe를 이용해도 확인 가능하다

셀렉터가 없는 리소스를 생성해서 외부 서버에 연결하는 방법
1. 셀렉터 없이 서비스를 생성
   - 엔드포인트가 생성되지 않는다
2. 직접 엔드포인트 생성
   - name 정보를 서비스와 동일하게 한다
   - ip를 직접 구성

ExternalName 서비스 
- ExternalName 서비스를 이용해서 실제 서비스의 FQDN을 사용하는 대신 서비스의 FQDN으로 외부 서비스에 접속할 수 있다
- 파드에서 실제 서비스의 이름과 위치가 숨겨져서 이후에 속성을 변경하거나 유형을 변경해서 다른 서비스를 가리키게 할 수 있다

## 외부 서비스 노출
노드 포트
- 각 워커노드에 특정 포트를 열어두고, 해당 포트로 요청을 받을 수 있다
   ```yaml
   spec:
      type: NodePort
      ports:
      - port: 80
        targetPort: 8080
        nodePort: 30123
   ```
- externalIP에 `<nodes>`라고 표시된다
- 노드포트를 통해서 내부로 들어오지만 이후에 서비스로 연결되고 서비스에서 다시 파드로 연결되는 구조
   - 이 과정에서 불필요한 네트워크 홉이 발생할 수 있는데, `spec.externalTrafficPolicy`를 `Local`로 설정(기본은 ClusterIP)하면 로컬에서 실행중인 파드를 선택하게 된다. 
   - 로드밸런서가 있다면 이러한 파드가 있는 노드로만 연결되도록 설정한다
- 노드포트로 연결을 수신하면 패킷에서 소스 네트워크 주소 변환이 일어나므로 패킷의 소스 IP가 변경된다. 파드는 실제 클라이언트의 IP를 볼 수 없다. 

로드 밸런서
- 노드포트랑 동일한데, 앞단에 로드밸런싱 기능이 추가된다
- 노드포트랑 동일하다는 말은 결국 노드로의 연결은 노드포트로 연결된다. 그래서 생성된 로드밸런서를 보면 노드포트가 설정되어 있다. 

인그레스
- 1개의 IP주소로 여러개의 서비스에 접근이 가능하도록 지원해준다
- HTTP 계층의 로드밸런서라고 생각하면 될 듯하다. 
- 인그레스 리소스와 인그레스 컨트롤러는 서로 다르니 헷갈리지 말자
   - 우리가 생성하는건 인그레스 리소스이다
- 동작 과정
   1. 클라이언트가 인그레스로 HTTP 요청을 보낸다
   2. 요청은 노드의 인그레스 컨트롤러에서 동작한다
   3. 인그레스 컨트롤러는 파드의 IP를 알기 위해서 인그레스 -> 서비스 -> 엔드포인트 정보를 통해서 파드의 정보를 확인한다
   4. 확인한 파드 정보를 바탕으로 클라이언트의 요청을 파드로 전달한다
- 인그레스를 이용해서 앞단에서 https 트래픽을 처리할 수도 있다
   - 인증서와 개인키는 시크릿 매니페스트에 저장한다
   - spec에서 tls 설정을 통해서 설정 가능하다

## 레디니스 프로브
정의
- 특정 파드가 클라이언트 요청을 수신할 수 있는지를 결정
- 초기화 검증 목적으로 사용된다

라이브니스프로브와 차이
- 라이브니스 프로브는 컨테이너가 정상적으로 동작하는지 체크하기 위함이고, 실패시 컨테이너를 재실행한다
- 레디니스 프로브는 컨테이너가 요청을 받을 준비가 되었는지 체크하기 위함이고, 실패시 서비스의 엔드포인트 리스트에서 제거된다

## 서비스 문제 해결
서비스로 파드에 엑세스 할 수 없을 경우 아래 내용을 확인해본다
- 외부가 아닌 클러스터 내에서 서비스의 클러스터 IP에 연결되는지 확인한다
- 서비스에 엑세스 할 수 있는지 확인하려고 서비스 IP로 핑을 할 필요는 없다
- 레디니스 프로브가 성공했는지 확인하라
- 엔드포인트를 조회해서 파드가 서비스에 포함되어 있는지 확인한다
- FQDN으로 접속하려고 할 때 작동하지 않는 경우 FQDN 대신 클러스터 IP를 사용해서 엑세스 할 수 있는지 확인하라
- 파드 IP에 직접 연결해서 파드가 올바른 포트에 연결되어 있는지 확인한다


## 궁금한 부분
이번 장을 통해서 현재 포인트서버에서 외부 서비스를 연결할 때는 파드에서 직접 연결을 하고 있는데 이 방법이 잘못되었나? 하는 생각이 들었음

외부 서비스 연결시 별도의 서비스를 구성하지 않고 직접 연결을 할 경우 어떤 이점이 있을까? 관리저 목적외에 성능의 이점은?

레디니스프로브와 라이브니스프로브의 검증을 서로 다르게 가져가야할까?

FQDN으로 접속하려고 할 때 작동하지 않느 ㄴ경우 FQDN 대신 클러스터 IP를 사용해서 엑세스 할 수 있는지 확인하라
- 클러스터 IP로 접속이 된다면 뭘 확인해야할까? dns 설정? 오타?